# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pfirmr2VbZqlxrqZ0I1SAkzRELQ2IzUz
"""

!pip install --upgrade numpy==1.25.2
!pip install --upgrade pandas_ta

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import yfinance as yf
import pandas_ta as ta

from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

import tensorflow as tf
from keras.models import Model
from keras.layers import LSTM, Dense, Activation, Input
from keras import optimizers
from keras.callbacks import EarlyStopping

np.random.seed(10)

def load_data_and_add_indicators(ticker='AAPL', start='2005-01-01', end='2025-02-21'):
    data = yf.download(tickers=ticker, start=start, end=end, auto_adjust=False)
    if data.empty:
        return pd.DataFrame()
    if isinstance(data.columns, pd.MultiIndex):
        data.columns = data.columns.droplevel(1)
    data['RSI'] = ta.rsi(data['Close'], length=15)
    data['EMAF'] = ta.ema(data['Close'], length=20)
    data['EMAM'] = ta.ema(data['Close'], length=100)
    data['EMAS'] = ta.ema(data['Close'], length=150)
    data.dropna(inplace=True)
    data = data[['Open','High','Low','Close','Adj Close','RSI','EMAF','EMAM','EMAS']]
    data.reset_index(inplace=True)
    return data

def create_sequences_and_split(df, backcandles=30):
    date_col = df['Date']
    numeric_df = df.drop('Date', axis=1)
    scaler = MinMaxScaler()
    data_scaled = scaler.fit_transform(numeric_df)
    n_features = numeric_df.shape[1]
    rows = data_scaled.shape[0]
    X, y = [], []
    for i in range(backcandles, rows):
        X.append(data_scaled[i-backcandles:i, :])
        y.append(data_scaled[i, 3])
    X = np.array(X)
    y = np.array(y).reshape(-1, 1)
    splitlimit = int(len(X) * 0.8)
    X_train, X_test = X[:splitlimit], X[splitlimit:]
    y_train, y_test = y[:splitlimit], y[splitlimit:]
    date_seq = date_col[backcandles:].reset_index(drop=True)
    date_train = date_seq[:splitlimit]
    date_test = date_seq[splitlimit:]
    return X_train, X_test, y_train, y_test, date_train, date_test, scaler, n_features

def build_lstm(input_shape):
    lstm_input = Input(shape=input_shape)
    x = LSTM(150)(lstm_input)
    x = Dense(1)(x)
    output = Activation('linear')(x)
    model = Model(inputs=lstm_input, outputs=output)
    adam = optimizers.Adam()
    model.compile(optimizer=adam, loss='mse')
    model.summary()
    return model

def train_and_evaluate_model(model, X_train, y_train, X_test, y_test, date_train, date_test, scaler, n_features, epochs=50, batch_size=8):
    early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)
    model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, shuffle=True, validation_split=0.1, verbose=1, callbacks=[early_stop])
    y_pred_scaled = model.predict(X_test)
    full_pred = np.zeros((len(y_pred_scaled), n_features))
    full_pred[:, 3] = y_pred_scaled.flatten()
    inv_pred = scaler.inverse_transform(full_pred)
    predictions = inv_pred[:, 3]
    full_ytest = np.zeros((len(y_test), n_features))
    full_ytest[:, 3] = y_test.flatten()
    actual = scaler.inverse_transform(full_ytest)[:, 3]
    mse = mean_squared_error(actual, predictions)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(actual, predictions)
    r2 = r2_score(actual, predictions)
    print("\nModel Performance Metrics:")
    print(f" - MSE: {mse:.4f}")
    print(f" - RMSE: {rmse:.4f}")
    print(f" - MAE: {mae:.4f}")
    print(f" - RÂ² Score: {r2:.4f}")
    recent_days = 5
    print(f"\nRecent {recent_days} Days (Actual vs Predicted):")
    for i in range(len(actual) - recent_days, len(actual)):
        print(f"Day {i} => Actual: {actual[i]:.4f}, Predicted: {predictions[i]:.4f}")
    y_pred_train_scaled = model.predict(X_train)
    full_pred_train = np.zeros((len(y_pred_train_scaled), n_features))
    full_pred_train[:, 3] = y_pred_train_scaled.flatten()
    predictions_train = scaler.inverse_transform(full_pred_train)[:, 3]
    full_ytrain = np.zeros((len(y_train), n_features))
    full_ytrain[:, 3] = y_train.flatten()
    actual_train = scaler.inverse_transform(full_ytrain)[:, 3]
    plt.figure(figsize=(16, 6))
    plt.plot(date_train, actual_train, label='Train Actual', color='blue')
    plt.plot(date_test, actual, label='Test Actual', color='black')
    plt.plot(date_test, predictions, label='Test Predicted', color='green')
    plt.title('Advanced LSTM Predictions')
    plt.xlabel('Date')
    plt.ylabel('Close Price USD ($)')
    plt.legend()
    plt.show()

def main():
    df = load_data_and_add_indicators()
    if df.empty:
        return
    X_train, X_test, y_train, y_test, date_train, date_test, scaler, n_features = create_sequences_and_split(df)
    if X_train.shape[0] == 0 or X_test.shape[0] == 0:
        return
    model = build_lstm(input_shape=(30, n_features))
    train_and_evaluate_model(model, X_train, y_train, X_test, y_test, date_train, date_test, scaler, n_features)

if __name__ == "__main__":
    main()